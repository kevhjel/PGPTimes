name: Scrape ClubSpeed leaderboard

on:
  workflow_dispatch:
  schedule:
    - cron: '0 9 * * 1'   # Mondays 09:00 UTC

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Ensure output dir exists and show drivers.csv
      - name: Prep data directory
        run: |
          mkdir -p data/debug_html
          echo "== drivers.csv =="
          if [ -f data/drivers.csv ]; then
            cat data/drivers.csv
          else
            echo "ERROR: data/drivers.csv not found (expected format: Name,ID per line)"
            ls -la data || true
          fi

      # --- Best-lap leaderboard (writes data/leaderboard.json) ---
      - name: Run leaderboard scraper (best laps)
        env:
          CUST_ID: ${{ secrets.CUST_ID }}             # REQUIRED (e.g., MTExNDczMQ==)
          START_YEAR: "2025"
          SITE_BASE_URL: ${{ secrets.SITE_BASE_URL }} # optional; defaults to PGP Kent when unset
          FILTER_DRIVERS: "0"
        run: |
          python -u scraper/scrape.py

      # --- Per-driver all laps (writes data/all_laps.csv + data/all_laps.json) ---
      - name: Run ALL-LAPS scraper (per driver)
        env:
          START_YEAR: "2025"
          SITE_BASE_URL: ${{ secrets.SITE_BASE_URL }}
          DEBUG: "1"                      # set to "0" after debugging
          DEBUG_MAX_DUMPS: "6"
          DEBUG_DUMP_VARIANTS: "default,print"
        run: |
          python -u scraper/scrape_all_laps.py

      # Diagnostics: verify outputs exist and print stats
      - name: Verify outputs
        run: |
          echo "== ls -l data =="
          ls -l data || true
          echo "== leaderboard.json =="
          if [ -f data/leaderboard.json ]; then
            wc -c data/leaderboard.json
            head -n 3 data/leaderboard.json || true
          else
            echo "MISSING: data/leaderboard.json"
          fi
          echo "== all_laps.csv =="
          if [ -f data/all_laps.csv ]; then
            wc -l data/all_laps.csv
            head -n 5 data/all_laps.csv || true
            tail -n 5 data/all_laps.csv || true
          else
            echo "MISSING: data/all_laps.csv"
          fi
          echo "== all_laps.json =="
          if [ -f data/all_laps.json ]; then
            wc -c data/all_laps.json
            head -n 20 data/all_laps.json || true
          else
            echo "MISSING: data/all_laps.json"
          fi
          echo "== debug_html (if any) =="
          ls -l data/debug_html || true

      # Upload the entire data/ folder as an artifact so you can download it directly
      - name: Upload data artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraped-data
          path: data
          if-no-files-found: warn

      # Commit updated data using plain git (most reliable)
      - name: Commit updated data (manual)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A data
          git commit -m "chore(data): update leaderboard, all_laps, and debug HTML" || echo "No changes to commit"
          git push

      # Show exactly what changed in the commit
      - name: Show last commit details
        run: |
          echo "== last commit =="
          git log -1 --name-status
